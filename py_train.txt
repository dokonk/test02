#from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.ensemble import RandomForestClassifier
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import pickle
import io
import csv
import pandas as pd
from io import StringIO
from math import sqrt
from sklearn import metrics
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np



def on_input(msg):

    #data = msg.body
    le = preprocessing.LabelEncoder()
    df1=pd.read_csv(StringIO(msg))
    df1.drop(['Loan_ID'], axis=1, inplace=True)
    df1['Gender']=df1['Gender'].fillna("Female")
    le.fit(df1['Gender'].to_list())
    df1['Gender']=le.transform(df1['Gender'])
    df1['Married']=df1['Married'].fillna("Yes")
    le.fit(df1['Married'].to_list())
    df1['Married']=le.transform(df1['Married'])
    le.fit(df1['Education'].to_list())
    df1['Education']=le.transform(df1['Education'])
    df1['Self_Employed']=df1['Self_Employed'].fillna("Yes")
    le.fit(df1['Self_Employed'].to_list())
    df1['Self_Employed']=le.transform(df1['Self_Employed'])
    df1['Property_Area']=df1['Property_Area'].fillna("Yes")
    le.fit(df1['Property_Area'].to_list())
    df1['Property_Area']=le.transform(df1['Property_Area'])
    df1['Dependents']=df1['Dependents'].fillna(0)
    df1['Dependents']=df1['Dependents'].replace("3+",3)
    df1['Loan_Status']=df1['Loan_Status'].fillna("Yes")
    le.fit(df1['Loan_Status'].to_list())
    df1['Loan_Status']=le.transform(df1['Loan_Status'])
    df1['ApplicantIncome']=df1['ApplicantIncome'].str.replace(',', '')
    ## split into Train and Testing for scoring the model
    X_train, X_test, y_train, y_test = train_test_split(df1.iloc[:,0:11], df1.iloc[:,11], test_size=0.2,shuffle=False) # 80% training and 20% test


    #build Model
    #model_sarimax = SARIMAX(train_data['GROSS_SALES_QTY'],order =(0,1,0), seasonal_order=(0,1,0,24))
    model_randomnforest=RandomForestClassifier(n_estimators=100)
    model_randomnforest.fit(X_train,y_train)

    #Score the model
    y_pred = model_randomnforest.predict(X_test)
    Accuracy=metrics.accuracy_score(y_test, y_pred)
    #rms_error =np.sqrt(mean_squared_error(test_data_val, df1['forecast'].dropna()))
    accu=str(Accuracy)

    ##output model Blob
    pickled_clf = pickle.dumps(model_randomnforest)
    model_blob=pickled_clf

    # send the metrics to the output port - Submit Metrics operator will use this to persist the metrics
    metrics_dict = {"Accuray of Prediction": accu}
    api.send("metrics", api.Message(metrics_dict))

    # create & send the model blob to the output port - Artifact Producer operator will use this to persist the model and create an artifact ID
    #model_blob = bytes("example", 'utf-8')
    api.send("modelBlob", model_blob)

api.set_port_callback("input", on_input)
